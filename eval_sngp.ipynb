{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from ignite.engine import Events, Engine\n",
    "from ignite.metrics import Accuracy, Average, Loss\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "from gpytorch.likelihoods import SoftmaxLikelihood\n",
    "\n",
    "from due import dkl\n",
    "from due.wide_resnet import WideResNet\n",
    "from due.rff_laplace import Laplace\n",
    "from due.resnet import resnet50, resnet110\n",
    "from due.densenet import densenet121\n",
    "\n",
    "from lib.datasets import get_dataset\n",
    "from lib.evaluate_ood import get_ood_metrics\n",
    "from lib.utils import get_results_directory, Hyperparameters, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: .//SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: .//SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "class args:\n",
    "    model = \"DenseNet121\"\n",
    "    rff_laplace = True\n",
    "\n",
    "_, _, _, cifar10_test_set = get_dataset('CIFAR10')\n",
    "_, _, _, cifar100_test_set = get_dataset('CIFAR100')\n",
    "_, _, _, svhn_test_set = get_dataset(\"SVHN\")\n",
    "_, _, _, tiny_imagenet_test_set = get_dataset(\"TinyImageNet\", root='./tiny-imagenet-200/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(5):\n",
    "    if args.model == \"WRN\":\n",
    "        feature_extractor = WideResNet(\n",
    "            32,\n",
    "            True,\n",
    "            True,\n",
    "            dropout_rate=0.3,\n",
    "            coeff=3,\n",
    "            n_power_iterations=1,\n",
    "        )\n",
    "    elif args.model == \"ResNet50\":\n",
    "        feature_extractor = resnet50(\n",
    "            spectral_normalization=True,\n",
    "            mod=False\n",
    "        )\n",
    "    elif args.model == \"ResNet110\":\n",
    "        feature_extractor = resnet110(\n",
    "            spectral_normalization=True,\n",
    "            mod=False\n",
    "        )\n",
    "    elif args.model == \"DenseNet121\":\n",
    "        feature_extractor = densenet121(\n",
    "            spectral_normalization=True,\n",
    "            mod=False\n",
    "        )\n",
    "\n",
    "    if args.rff_laplace:\n",
    "        # Defaults from SNGP in uncertainty-baselines\n",
    "        if args.model == \"WRN\":\n",
    "            num_deep_features = 640\n",
    "        elif args.model == \"ResNet50\" or args.model == \"ResNet110\":\n",
    "            num_deep_features = 2048\n",
    "        elif args.model == \"DenseNet121\":\n",
    "            num_deep_features = 1024\n",
    "        num_gp_features = 128\n",
    "        num_random_features = 1024\n",
    "        normalize_gp_features = True\n",
    "        lengthscale = 2\n",
    "        mean_field_factor = 25\n",
    "        num_data = 50000\n",
    "        num_classes = 100\n",
    "\n",
    "        model = Laplace(\n",
    "            feature_extractor,\n",
    "            num_deep_features,\n",
    "            num_gp_features,\n",
    "            normalize_gp_features,\n",
    "            num_random_features,\n",
    "            num_classes,\n",
    "            num_data,\n",
    "            500,\n",
    "            mean_field_factor,\n",
    "            lengthscale,\n",
    "        )\n",
    "\n",
    "    model = model.cuda()\n",
    "    model.load_state_dict(torch.load(f'./runs/cifar100/densenet121/Run{i+1}/model.pt'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: .//SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: .//SVHN/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: .//SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: .//SVHN/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: .//SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: .//SVHN/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: .//SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: .//SVHN/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: .//SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: .//SVHN/test_32x32.mat\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "eces = []\n",
    "aurocs_svhn = []\n",
    "aurocs_tiny_imagenet = []\n",
    "\n",
    "for i in range(5):\n",
    "    accuracy, ece, auroc_svhn, _ = get_ood_metrics(\"CIFAR100\",\n",
    "                                                   \"SVHN\",\n",
    "                                                   models[i])\n",
    "    _, _, auroc_tiny_imagenet, _ = get_ood_metrics(\"CIFAR10\",\n",
    "                                                   \"TinyImageNet\",\n",
    "                                                   models[i],\n",
    "                                                   root='./tiny-imagenet-200/')\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    eces.append(ece)\n",
    "    aurocs_svhn.append(auroc_svhn)\n",
    "    aurocs_tiny_imagenet.append(auroc_tiny_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71946+-0.015414233681892852\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "accuracies = torch.tensor(accuracies)\n",
    "mean_acc = torch.mean(accuracies)\n",
    "std_acc = torch.std(accuracies) / math.sqrt(accuracies.shape[0])\n",
    "\n",
    "print (f'{mean_acc.item()}+-{std_acc.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09738753736019135+-0.010322741232812405\n"
     ]
    }
   ],
   "source": [
    "eces_item = []\n",
    "for ece in eces:\n",
    "    eces_item.append(ece.item())\n",
    "\n",
    "eces_item = torch.tensor(eces_item)\n",
    "mean_ece = torch.mean(eces_item)\n",
    "std_ece = torch.std(eces_item) / math.sqrt(eces_item.shape[0])\n",
    "\n",
    "print (f'{mean_ece.item()}+-{std_ece.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8199721473570989+-0.012109729267866303\n"
     ]
    }
   ],
   "source": [
    "aurocs_svhn = torch.tensor(aurocs_svhn)\n",
    "mean_auroc_svhn = torch.mean(aurocs_svhn)\n",
    "std_auroc_svhn = torch.std(aurocs_svhn) / math.sqrt(aurocs_svhn.shape[0])\n",
    "\n",
    "print (f'{mean_auroc_svhn.item()}+-{std_auroc_svhn.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aurocs_cifar100 = torch.tensor(aurocs_cifar100)\n",
    "# mean_auroc_cifar100 = torch.mean(aurocs_cifar100)\n",
    "# std_auroc_cifar100 = torch.std(aurocs_cifar100) / math.sqrt(aurocs_cifar100.shape[0])\n",
    "\n",
    "# print (f'{mean_auroc_cifar100.item()}+-{std_auroc_cifar100.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5476418940000001+-0.001489154140246562\n"
     ]
    }
   ],
   "source": [
    "aurocs_tiny_imagenet = torch.tensor(aurocs_tiny_imagenet)\n",
    "mean_auroc_tiny_imagenet = torch.mean(aurocs_tiny_imagenet)\n",
    "std_auroc_tiny_imagenet = torch.std(aurocs_tiny_imagenet) / math.sqrt(aurocs_tiny_imagenet.shape[0])\n",
    "\n",
    "print (f'{mean_auroc_tiny_imagenet.item()}+-{std_auroc_tiny_imagenet.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
